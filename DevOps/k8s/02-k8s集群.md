# Kubernets 集群

Kubernets用于协调高度可用的计算机集群，这些计算机集群被连接并作为单个单元工作。Kubernets在一个集群上以更有效的方式自动分发和调度容器应用程序。Kubernets集群由两种资源组成：

- Master：集群的调度节点
- Nodes：应用程序实际运行的节点

Kubernets的集群部署方式有三种方式：kubeadm、minikube和二进制包，前两者属于自动化部署，简化部署操作，同样它也屏蔽了很多细节，对各个模块的了解比较少。

## 1. 环境准备与规划

| 角色   | IP            | 组件                                                         |
| ------ | ------------- | ------------------------------------------------------------ |
| master | 192.168.31.44 | etcd、kube-apiserver、kube-controller-manager、kube-scheduler、docker |
| node01 | 192.168.31.45 | kube-proxy，kubelet、docker                                  |
| node01 | 192.168.31.46 | kube-proxy，kubelet、docker                                  |

- 查看防火墙状态（ 关闭状态显示 not running ，开启状态显示running）

  ```bash
  firewall-cmd --state
  ```

- 关闭防火墙，并禁止开机启动

  ```bash
  systemctl stop firewalld
  systemctl disable firewalld
  ```

- 获取二进制包

  Kubernets二进制包下载地址是

  ```
  https://github.com/kubernetes/kubernetes
  ```

  根据版本选择相应的`CHANGELOG-x.x.md`，下载相应的版本

  > 注意上面的文件下载需要vpn连接才可以完成

### 1.1 Master 安装

#### 1.1.1 docker 安装

安装的是`docker-engine`，不是`docker-ce`

- 需要保证yum包更新到最新

```bash
  $ yum update
```

- 设置yum源

```bash
  $ vim /etc/yum.repos.d/docker.repo
```

`docker.repo`文件内容

```bash
  [dockerrepo]
  name=Docker Repository
  baseurl=https://yum.dockerproject.org/repo/main/centos/$releasever/
  enable=1
  gpgcheck=1
  gpgkey=https://yum.dockerproject.org/gpg
```

- 安装 docker

```bash
  $ yum install -y docker-engine
```

  会安装最新版本

- 查看版本cd 

```bash
  $ docker -v
  Docker version 18.09.8, build 0dd43dd87f
```

#### 1.1.2 etcd 安装

etcd是Kubernets集群中的主要服务，在Kubernets安装前需要首先安装与启动

- 下载二进制文件

  ```
  https://github.com/etcd-io/etcd
  ```

  从`release`中选择需要安装的版本信息

- 安装 lrzsz

```bash
$ yum install -y lrzsz
```

- 创建k8s目录

```
$ mkdir /usr/local/k8s
```

- 上传文件

```bash
$ rz
```

弹出选择框，选择文件上传到指定目录

```bash
$ ls -ltr
total 10992
-rw-r--r-- 1 root root 11254519 Jul 21 01:08 etcd-v3.3.9-linux-amd64.tar.gz
```

- 解压文件

```bash
$ tar -zxvf etcd-v3.3.9-linux-amd64.tar.gz
```

- 复制文件

```bash
$ cd etcd-v3.3.9-linux-amd64
$ cp etcd etcdctl /usr/bin/
```

- etcd.service文件创建

  编辑 systemd 服务文件

```bash
$ vim /usr/lib/systemd/system/etcd.service
```

文件内容

```bash
[Unit]
Description=Etcd Server
After=network.target
[Service]
Type=Simple
EnvironmentFile=/etc/etcd/etcd.conf
WorkingDirectory=/var/lib/etcd/
ExecStart=/usr/bin/etcd
Restart=on-failure
[Install]
WantedBy=multi-user.target
```

创建文件

```
$ mkdir /var/lib/etcd
$ mkdir /etc/etcd
$ touch /etc/etcd/etcd.conf
```

- 启动与测试etcd服务

```bash
$ systemctl daemon-reload
$ systemctl enable etcd.service
$ systemctl start etcd.service
# 健康状态检查
$ etcdctl cluster-health
member 8e9e05c52164694d is healthy: got healthy result from http://localhost:2379
cluster is healthy
```

出现上面的结果，代表etcd服务安装完成

#### 1.1.3 kube-apiserver

* 上传文件

```bash
$ rz
```

* 解压文件

```bash
$ tar -zxvf kubernetes-server-linux-amd64.tar.gz
```

* 文件复制

将kube-apiserver、kube-controller-manager、kube-scheduler、kubelet二进制命令文件复制到/usr/bin/目录

```bash
$ cd /usr/local/k8s/kubernetes/server/bin
$ cp kube-apiserver kube-controller-manager kube-scheduler kubelet /usr/bin/
```

* 配置服务

  * kube-apiserver

    编辑 systemd 服务文件
  
  ```bash
$ vim /usr/lib/systemd/system/kube-apiserver.service
  ```

  kube-apiserver.service服务文件
  
  ```bash
  [Unit]
  Description= Kubernets Api Server
  Documentation=https://github.com/kubernets/kubernetes
  After=etcd.target
  Wanted=etcd.target
  [Service]
  EnvironmentFile=/etc/kubernetes/apiserver
  ExecStart=/usr/bin/kube-apiserver $KUBE_API_ARGS
  Restart=on-failure
  Type=notify
  [Install]
WantedBy=multi-user.target
  ```

  文件创建
  
  ```bash
  $ mkdir /etc/kubernetes
  $ touch /etc/kubernetes/apiserver
$ vim /etc/kubernetes/apiserver
  ```

  输入如下内容
  
  ```bash
KUBE_API_ARGS="--storage-backend=etcd3 --etcd-servers=http://127.0.0.1:2379 --insecure-bind-address=0.0.0.0 --insecure-port=8080 --service-cluster-ip-range=169.169.0.0/16 --service-node-port-range=1-65535 --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount, DefaultStorageClass,ResourceQuota --logtostderr=false --log-dir=/var/log/kubernetes --v=2"
  ```
  
  > 参数说明： 
  > --storage-backend ：指定 etcd 版本。
  > --etcd-servers ：指定 etcd 服务器地址和端口。 
  > --insecure-bind-address ：指定 api-server 非安全方式绑定的地址。0.0.0.0 表示所有地址。 
  > --insecure-port ：指定 api-server 非安全方式启用的端口号。 
  > --service-cluster-ip-range ：指定集群 Cluster IP 网段，如果后续需要使用网络插件这里需要按照网络插件要求的网段配置。 
  > --service-node-port-range ：指定集群中 Service 可以映射物理机端口号范围 
  > --admission_control ：Kubernetes 集群的准入控制设置，各控制模块以插件形式依次生效。 
  > --logtostderr ：指定为 false 时将错误日志写入日志文件而非 标准输出。 
  > --log-dir ：日志保存路径。 
  > --v ：日志级别
  
* 通过 systemd 启动 kube-apiserver 并设置为开机自启动

```bash
$ systemctl daemon-reload
$ systemctl start kube-apiserver
$ systemctl enable kube-apiserver
# 之后可以通过 status 来检查服务器运行状态
$ systemctl status kube-apiserver
```

#### 1.1.4 kube-controller-manager

* 配置服务

  * kube-controller-manager.service

    编辑 systemd 服务文件

  ```bash
  $ vim /usr/lib/systemd/system/kube-controller-manager.service
  ```

  kube-controller-manager.service 文件内容

  ```bash
  [Unit]
  Description=Kubernetes Controller Manager
  After=kube-apiserver.service
  Requires=kube-apiserver.service
  
  [Service]
  EnvironmentFile=/etc/kubernetes/controller-manager
  ExecStart=/usr/bin/kube-controller-manager $KUBE_CONTROLLER_MANAGER_ARGS
  Restart=on-failure
  LimitNOFILE=65536
  
  [Install]
  WantedBy=multi-user.target
  ```

  环境变量文件 /etc/kubernetes/controller-manager 中定义了 kube-controller-manager 启动参数 KUBE_CONTROLLER_MANAGER_ARGS。我们创建这个文件并填入如下内容

  ```bash
  $ touch  /etc/kubernetes/controller-manager
  $ vim  /etc/kubernetes/controller-manager
  ```

  controller-manager文件内容

  ```bash
  KUBE_CONTROLLER_MANAGER_ARGS="--master=http://192.168.31.44:8080 --logtostderr=false --log-dir=/var/log/kubernetes --v=2"
  ```

  > 参数说明：
  >
  > --master ：指定 API-server 的URL地址

#### 1.1.5 kube-scheduler

* 配置服务

  * kube-scheduler.service

  编辑文件

  ```bash
  $ vim /usr/lib/systemd/system/kube-scheduler.service
  ```

  文件内容

  ```bash
  [Unit]
  Description=Kubernetes Scheduler Server
  After=kube-apiserver.service
  Requires=kube-apiserver.service
  
  [Service]
  EnvironmentFile=/etc/kubernetes/scheduler
  ExecStart=/usr/bin/kube-scheduler $KUBE_SCHEDULER_ARGS
  Restart=on-failure
  LimitNOFILE=65536
  
  [Install]
  WantedBy=multi-user.target
  ```

  环境变量文件 /etc/kubernetes/scheduler 中定义了 kube-scheduler 启动参数 KUBE_SCHEDULER_ARGS。我们创建这个文件并填入如下内容

  ```bash
  $ mkdir /var/log/kubernetes
  $ touch /etc/kubernetes/scheduler
  $ vim   /etc/kubernetes/scheduler
  ```

  scheduler文件内容

  ```bash
  KUBE_SCHEDULER_ARGS="--master=http://192.168.31.44:8080 --logtostderr=false --log-dir=/var/log/kubernetes --v=2"
  ```

  > 参数说明：
  >
  > --master ：指定 API-server 的URL地址
  >
  > --log-dir：日志路径

  安装完 kube-controller-manager 和 kube-scheduler 之后将其启动并设置为开机自启动

  ```bash
  $ systemctl daemon-reload
  $ systemctl start kube-controller-manager kube-scheduler
  $ systemctl enable kube-controller-manager kube-scheduler
  # 同样，启动之后可以通过 systemctl status XXXX 来检查服务的状态
  $ systemctl status kube-controller-manager
  $ systemctl status kube-scheduler.service
  ```

#### 1.1.6 master 启动

  ```bash
$ systemctl daemon-reload
# etcd
$ systemctl enable etcd.service
$ systemctl start etcd.service
# 健康状态检查
$ etcdctl cluster-health
member 8e9e05c52164694d is healthy: got healthy result from http://localhost:2379
cluster is healthy

# apiserver
$ systemctl start kube-apiserver
$ systemctl enable kube-apiserver
# 之后可以通过 status 来检查服务器运行状态
$ systemctl status kube-apiserver

# kube-controller-manager
$ systemctl start kube-controller-manager
$ systemctl enable kube-controller-manager
# 同样，启动之后可以通过 systemctl status kube-controller-manager  来检查服务的状态
$ systemctl status kube-controller-manager

# kube-scheduler
$ systemctl start kube-scheduler
$ systemctl enable kube-scheduler
# 同样，启动之后可以通过 systemctl status kube-scheduler 来检查服务的状态
$ systemctl status kube-scheduler.service

  ```

### 1.2 Node节点安装

node 节点上需要安装的服务有 docker 、kubelet 和 kube-proxy。

#### 1.2.1 docker-ce

* Ubuntu

```bash
# step 1: 安装必要的一些系统工具
$ sudo apt-get update
$ sudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common
# step 2: 安装GPG证书
$ curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -
# Step 3: 写入软件源信息
$ sudo add-apt-repository "deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"
# Step 4: 更新并安装 Docker-CE
$ sudo apt-get -y update
$ sudo apt-get -y install docker-ce
```

* CentOS

```bash
# step 1: 安装必要的一些系统工具
$ yum update
$ yum install -y yum-utils device-mapper-persistent-data lvm2
# step 2: 卸载旧版本
$ yum remove docker  docker-common docker-selinux docker-engine
# step 3: 卸载旧版本设置yum源
$ yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
# 阿里源
$ yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
# Step 4: 更新并安装 Docker-CE
$ yum install docker-ce
```

* 启动并开机自启

```bash
# 启动
$ systemctl start docker
# 开机自启
$ systemctl enable docker
# 状态检查
$ systemctl status docker
```

####  1.2.2 kubelet

- 安装 lrzsz

```bash
$ yum install -y lrzsz
```

- 创建k8s目录

```
$ mkdir /usr/local/k8s
```

- 上传文件

```bash
$ rz
```

弹出选择框，选择文件上传到指定目录

```bash
$ ls -ltr
total 10992
-rw-r--r-- 1 root root 422572807 Jul 20 19:06 kubernetes-server-linux-amd64.tar.gz
```

- 解压文件

```bash
$ tar -zxvf kubernetes-server-linux-amd64.tar.gz
```

- 复制文件

```bash
$ cd kubernetes/server/bin
$ cp kube{let,-proxy} /usr/bin/
```

* kubelet.service

编辑 systemd 服务文件 /usr/lib/systemd/system/kubelet.service

```bash
$ vim /usr/lib/systemd/system/kubelet.service
```

文件内容

```bash
[Unit]
Description=Kubernetes Kubelet Server
After=docker.service
Requires=docker.service

[Service]
WorkingDirectory=/var/lib/kubelet
EnvironmentFile=/etc/kubernetes/kubelet
ExecStart=/usr/bin/kubelet $KUBELET_ARGS
Restart=on-failure
KillMode=process

[Install]
WantedBy=mulit-user.target
```

> WorkingDirectory 指定的路径是 kubelet 的数据目录，需要在服务运行前创建提前创建。

* 创建文件夹

```bash
$ mkdir /var/lib/kubelet
$ mkdir /etc/kubernetes
$ mkdir /var/log/kubernetes
```

* 参数定义

环境变量文件 /etc/kubernetes/kubelet 中定义了 kubelet 启动参数 KUBELET_ARGS。我们创建这个文件

```bash
$ touch /etc/kubernetes/kubelet
$ vim   /etc/kubernetes/kubelet
```

输入内容

```bash
KUBELET_ARGS="--kubeconfig=/etc/kubernetes/kubeconfig --hostname-override=192.168.31.45 --logtostderr=false --log-dir=/var/log/kubernetes --v=2 --fail-swap-on=false"
```

> 参数说明：
>
> --kubeconfig: master服务器描述信息，用于连接master
>
> --api-servers ：指定 apiserver 的URL地址。
>
> --hostname-override ：指定注册到 apiserver 时本节点的名称。
>
> --fail-swap-on=false

* kubeconfig

```yaml
apiVersion: v1
kind: Config
clusters:
 - cluster:
    server: http://192.168.31.44:8080
   name: local
context:
 - context:
    cluster: local
   name: k8scontext
current-context: k8scontext
```

* 通过 systemd 启动 kubelet 并设置为开机自启动

```bash
$ systemctl daemon-reload
$ systemctl start kubelet
$ systemctl enable kubelet
# 之后可以通过 status 来检查服务器运行状态
$ systemctl status kubelet
```

#### 1.2.3  kube-proxy

- kube-proxyservice

编辑 systemd 服务文件 /usr/lib/systemd/system/kube-proxy.service

```bash
vim /usr/lib/systemd/system/kube-proxy.service
```

文件内容

```bash
[Unit]
Description=Kubernetes Kube-Proxy Server
After=network.service
Requires=network.service

[Service]
EnvironmentFile=/etc/kubernetes/proxy
ExecStart=/usr/bin/kube-proxy $KUBE_PROXY_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
```

- 创建文件夹

```bash
$ mkdir /var/lib/kubelet
$ mkdir /etc/kubernetes
$ mkdir /var/log/kubernetes
```

- 参数定义

环境变量文件 /etc/kubernetes/proxy中定义了 proxy启动参数 KUBE_PROXY_ARGS。我们创建这个文件

```bash
$ touch /etc/kubernetes/proxy
$ vim   /etc/kubernetes/proxy
```

输入内容

```bash
KUBE_PROXY_ARGS="--master=http://192.168.31.44:8080 --logtostderr=false --log-dir=/var/log/kubernetes --v=2"
```

通过 systemd 启动 kubu-proxy 并设置为开机自启动

```bash
$ systemctl daemon-reload
$ systemctl start kube-proxy
$ systemctl enable kube-proxy
# 之后可以通过 status 来检查服务器运行状态
$ systemctl status kube-proxy
```

node 节点设置完成后， 如果 master 节点上有 kubernetes 的命令行管理软件 kubectl ，就可以使用kubectl 查看到新增加的节点。kubectl 的二进制文件可以从 kubernetes-server-linux-amd64.tar.gz 中找到。



```bash

$ cp kubernetes/server/bin/kubectl /usr/bin/
$ chmod +x /usr/bin/kubectl
$ kubectl get node
# 输出为
# NAME      STATUS     AGE       VERSION
# u16-2     NotReady   17m       v1.6.0
```